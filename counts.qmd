# Chi-squared analysis of count data

```{r}
#| include: false
source("_common.R")
```

\vspace{-10mm}

```{r, include = FALSE}
library(tidyverse)
library(here)
```

```{r}
# we use the fabulous openintro here only for its colour scheme
library(openintro)
data(COL)
fill_colour1<-COL['blue','f3']
# fill_colour1 <- "#b3cde3"
fill_colour2<-COL['red','f6']
fill_colour3<-COL['blue','f1']
line_colour<-COL['blue','full']
func_colour<-"darkblue"
point_colour<-COL['blue','full']
error_colour<-COL['red','full']
```

A chi-square analysis is used when our data are in the form of raw counts for two or more categorical groups eg pea plants with either yellow peas or green peas, survival rate of mice if they took drug A or took drug B, etc. Each independent observation must definitely belong to either one group or the other, and there should be no replicates. That is, for each category we should have just have one count.

What we do is compare the counts we got to some *expected* value according either to chance or to some prior theory.

For example:

-   If we were tossing a fair coin 1000 times we would *expect* 500 heads and 500 tails, ie heads and tails in the proportion 1:1. In reality, if the coin were fair, we would probably get roughly the same number of heads and tails, but not exactly 500 of each. How far from 50:50 would the proportion of heads and tails have to be before we would be justified in rejecting the idea that the coin is fair?

-   If we threw a fair dice a large number of times we would *expect* each possible score, from 1 to 6, to occur the same number of times. ie each score would occur 1/6th of the time. In reality we would probably get each score *roughly* 1/6 of the time, but not exactly 1/6. How far from the expected proportions could the numbers of each score have to get before we would be justified in thinking that the dice was not fair?


## Chi-square goodness of fit test

In a chi-square 'goodness of fit' test, we are testing data where we have a number of counts for each of two or more possible outcomes of some procedure (heads/tails, dice scores, pea colour etc). We have an idea of how these counts should be distributed under some null hypothesis (the coin is fair, the dice is fair, genetic inheritance works in this or that way etc). The chi-square goodness of fit test tests how likely it is we would have got the counts we actually got if that null hypothesis were correct. We are testing how well our actual counts 'fit' the expected values. 

In a typical software implementation of the test, such as in R, we give it the counts we actually got for each possible outcome and also the expected proportion for each outcome. The test then gives us a p-value, a probability, for how likely it is that we would have got the counts we actually got, or counts even further from the null hypothesis, if that null hypothesis were correct. If this p-value is too small, and by that we usually mean less than 0.05, then we reject the null hypothesis.

### Example: Mendelian Genetics

If the basic idea of Mendelian inheritance with independent assortment involving a single gene is correct, then we would expect that if we crossed a large number of pea plants that were heterozygous for yellow and green pea colour, as in the F1 generation shown in @fig-mendelian-inheritance with yellow being dominant, then the offspring in the F2 generation would in the long run be expected to have yellow:green peas in the ratio 3:1 (plants with genotypes YY, Yy, yY would all have yellow seeds and only those with yy would have green seeds). In practice, if the inheritance *were* according to the simplest type of Mendelian inheritance (ie involving just one gene, amongst other things) we would probably get yellow:green offspring in a ratio that was *approximately* but not exactly 3:1. How far from 3:1 would the ratio need to be before we would justified in claiming that the outcome was inconsistent with the Mendelian prediction?

```{r}
#| label: fig-mendelian-inheritance
#| fig-cap: "An outline of Mendel's green:yellow pea crossing study. In the F1 generation there would necessarily be 100% yellow plants with genotype Yy. In the F2 generation the ratio 3:1 yellow:green is what is *expected* if random Mendelian inheritance is the underlying mechanism. In reality we would probably not see excatly that ratio. A chi-square goodness of fit test tells us how likely it is we would get the ratio we got, or a more extreme ratio, *if* Mendelian inheritance were correct. Source: Khan Academy"

myimages<-here::here("figures","mendelian_pea_plants.png")
knitr::include_graphics(myimages)
```

Suppose we have crossed pea plants that were all heterozygous for yellow/green pea colour. In the F2 generation we get 176 offspring, of which 125 are yellow and 51 are green. These are the *observed* counts of yellow and green pea plants. 
The *expected* counts of yellow and green are found by simply dividing the total count of offspring, 176, in the ratio 3:1, giving us an expected 132 yellow pea plants and an expected 44 green pea plants in the offspring F2 generation.

The data here are raw counts, and an individual pea plant offspring contributes either to the yellow count or to the green count, but not to both.

**Doing the chi-square test manually**

You would not normally do this, you would use software such as R, but for learning purposes let us go as far as we can in implementing a chi-square test on this data ourselves just to see the process behind it, then we can see how easy it is to do the test in R.

What we need to do is to calculate from our data a number that tells us how likely is it that we would have got totals for yellow and green pea plants as far or further from the expected 3:1 ratio as we did, if the null hypothesis of Mendelian inheritance were correct. 

That is the very definition of a p-value! So that is what we need to calculate, a p-value.

It turns out that this p-value an be calculated from a number derived from the data that we call the **chi-square statistic**. This number is defined in such a way that the further your actual counts are from thier expected values, the bigger it is.

It is calculated by looking at the squared difference, for each count, between the observed value and the expected value. The squared thing is because we don't care if the observed value is less than or more than the expected value. It is by how much that matters. 

Here is the expression for the chi-square statistic:

$$
\begin{align}
\chi^2 &= \sum_{i=\text{Y,G}}\frac{(O_i-E_i)^2}{E_i}\\ &=\frac{(O_\text{Y}-E_\text{Y})^2}{E_\text{Y}} + \frac{(O_\text{G}-E_\text{G})^2}{E_\text{G}}
\end{align}
$$
The first line is just a more compact way of witing the second line, where the $\sum$ symbol means 'sum over' a yellow peas term (Y) and a green peas term (G), as laid out in the second line. $O_\text{Y}$ and $O_\text{G}$ mean the observed numbers of yellow and green pea plants respectively, while $E_\text{Y}$ and $E_\text{G}$ mean the expected numbers of each.

Defined in this way, the chi-square statistic $\chi^2$is a number that will always be positive (because it is the sum of squared terms, and they are always positive, divided by an expected number, which can also only be positive) and will be bigger the further from the expected values our observed values turn out to be.

It is also a number that will vary each time you repeat the study because while the expected values $E_i$ are fixed, the observed values $O_i$ will vary from one occasion to the next. In fact, if you were to repeat the study many times and each time calculate the chi-sqare statistic you would find that it follows one of a known family of distributions, the so-called (who would have thought it?) chi-square distributions, provided each count is greater than about five. 

To determine which one among them is followed by our own chi-squared statistic we need to know one more thing, the so-called *degrees of freedom*. This is a term that crops up often when using statistical tests. Roughly speaking, it refers to the number of independent pieces of information that are used in arriving at a result, given whatever constraints surround the problem. In our case, the constraint was that there were 176 pea plants in total in the F2 generation. That meant that only one of the sub-totals for each of the colours could be freely chosen. Once it was known the other could be determined as the difference between it and the total: if there are 176 plants in total and 125 of them are yellow, then the green total *has* to be 176 - 125 = 51. So, in our case the degrees of freedom is one.

Finally, knowing the chi-square statistic for our data, and knowing the degrees of freedom for our design, and thus knowing which chi-squae distribution is followed by our statistic, we can calculate the probability of getting a chi-squared value as great or greater than the one we got. This in turn means (because it is the same thing in the end) that we can calculate the probability of getting data as far or further from the the expected values as the numbers we got - the magic p-value. We get software such as R to do this last bit for us.

Finally, on that basis we can either reject or fail to reject the null hypothesis.

Let's have a go:

First we calculate our chi-squared statistic:

$$
\begin{align}
\chi^2 &=\frac{(O_\text{Y}-E_\text{Y})^2}{E_\text{Y}} + \frac{(O_\text{G}-E_\text{G})^2}{E_\text{G}}\\
&=\frac{(125-132)^2}{132} + \frac{(51-44)^2}{44}\\
&=1.48
\end{align}
$$


```{r}
pchisq(1.48,1, lower.tail=FALSE)
```


**Doing the chi-square test in R**

What we do in R is use the `chisq.test()` function to see how likely it is we would have got counts of 125 and 51 if the null hypothesis, with its expected counts in the ratio 3:1, were true.

We do it like this:

`chisq.test(c(125,51),p=c(0.75,0.25))`

There are two arguments. The first is the counts we got, which we enter as a 'vector' `c(z,y,....)`, so we write `c(130,46)`. The second is a vector of the proportions we expect for the two counts, where these proportions should add up to one. So for our expected 3:1 ratio we enter `c(0.75,0.25)`.

Let's do it: type the above function into the console window (bottom left). You will get an output something like this:

```{r,echo=FALSE}
chisq.test(c(125,51),p=c(0.75,0.25))
```

This output is typical of tests done in R. We get the 'test statistic' whose name varies depending on the test. Here it is called `X-squared`, pronounced `chi-squared`. This is a number that the test calculates, based on the data you have given it. For the most part, we don't need to worry about how it does that. Then there is the p-value, which is the probability of getting this test statistic if the null hypothesis were true.

In this case, we see that the p-value is 0.223, which is large. We could very plausibly have got yellow:green numbers of 125 and 51 if the null hypothesis were true, so we cannot reject that null hypothesis. In other words, our data are consistent at the 5% significance level with the predictions of simple Mendelian inheritance.

**Reporting the result in English**

In English, we might report this result as:

*We found counts of 125 yellow plants and 51 green plants, which are consistent at the 5% significance level with the predictions of Mendelian inheritance (chi-squared test, X-squared = 1.48, df = 1,  p=0.223).*

Note that we do not say we have proved Mendelian inheritance to be correct. We haven't. We never prove things in science. We haven't said anything about the truth of the null hypothesis. All we can say is whether our data are or are not consistent with the null hypothesis. In this case they are. We then report the test we used and the values of the test statistic and p-value. Other tests might give you other details to report too.



### Testing if Hardy Weinberg Equilibrium is satisfied

Suppose we have a population of people in which there is a gene that has two alleles A and a, where A is dominant. Suppose that being homozygous in the recessive allele a means that the individual is affected by sickle cell anemia. Being heterozygous Aa means that the individual is not affected but is a carrier and may pass the a allele on to their progeny. Those who are homozygous in the dominant allele A are unaffected.

**Observed Frequencies**

Suppose in a population of $N=1100$ people the observed numbers of each genotype are as follows:

$$
\begin{align}
\text{AA}_\text{O} &= 756\\
\text{Aa}_\text{O} &= 200\\
\text{aa}_\text{O} &= 144\\
\end{align}
$$


```{r}
AA_o <- 756 # observed unaffected
Aa_o <- 200 # observed carriers
aa_o <- 144 # observed affected
N <- AA_o +Aa_o + aa_o # total population
```

where the subscript letter $O$ denotes 'Observed'

**Calculate allele frequencies**

Each person in the population carries two copies of the gene so the total number of alleles is $2N$. We use $p$ and $q$ to denote the proportion of these that are $A$ and $a$ alleles respectively.

Each person who is homozygous in $\text{A}$ carries two copies of the $A$ allele while each heterozygous person carries one. $p$, the proportion of all alleles that are $A$, will be the number of $A$ alleles in the population divided by the total number of alleles and will will be given by

$$
\begin{align}
p &= \frac{2 \times \text{AA}_\text{O} + \text{Aa}_\text{O} }{2N}\\
&=\frac{2\times 756 + 200}{2\times 1100}\\
&=\frac{1712}{2200}\\
&=0.778
\end{align}
$$


Similarly, $q$, the proportion of all alleles that are $a$, will be the number of $a$ alleles in the population divided by the total number of alleles and will will be given by

$$
\begin{align}
q &= \frac{2 \times \text{aa}_\text{O} + \text{Aa}_\text{O} }{2N}\\
&=\frac{2\times 144 + 200}{2\times 1100}\\
&=\frac{488}{2200}\\
&=0.222
\end{align}
$$


```{r}
p <- (2*AA_o + Aa_o) / (2 * N) # frequency of A allele
q <- (2*aa_o + Aa_o) / (2 * N) # frequency of a allele
p + q
```

**Expected under HWE**

Under Hardy-Weinberg equilibrium, a key assumption is that there is random mating among individuals in the population. This means that the probability of an individual having any of the three possible genotypes is the product of the frequencies of the two alleles present for that genotype.

Hence, under Hardy-Weinberg individual, we would *expect* the following genotype frequencies:

Genotype | Expected Frequency
---------|----------
AA       | $p^2$
Aa       | $2pq$
aa       | $q^2$


```{r}
AA_e <- p^2 * N
Aa_e <- 2 * p * q * N
aa_e <- q^2 * N

```

The numbers we would expect for each genotype, if Hardy-Weinberg equilibrium held would be these frequencies multipled by the total populations:

Genotype | Expected Frequency | Expected Number
---------|--------------------|---------------
AA       | $p^2$ | $p^2 \times N = 0.788^2 \times 1100 = 666$
Aa       | $2pq$ | $2pq \times N = 2\times 0.788\times 0.222 \times 1100 = 380$
aa       | $q^2$ | $q^2 \times N = 0.222^2 \times 1100 = 54$


**Calculate Chi-squared statistic**

$$
\begin{align}
\chi^2 &= \sum_{i=1}^3\frac{(O_i-E_i)^2}{E_i}\\
&=\frac{(756-666)^2}{666} +\frac{(200-380)^2}{380} + \frac{(144-54)^2}{54}\\
&=246.5
\end{align}
$$

```{r}
chi_sq <- (AA_o-AA_e)^2 / AA_e + (Aa_o-Aa_e)^2 / Aa_e + (aa_o - aa_e)^2 / aa_e
chi_sq
```

**Calculate degrees of freedom**

This is the number of independent pieces of information used in calculating the test statistics $\chi^2$. In problems like this it turns out to. be equal to the number of gneotypes minus the number of alleles, so in this case the answer is 3 - 2 = 1. The underlying reason for this is that the expected genotype numbers are determined by the allele frequencies p and q. Since these must add up to one, that means that if either p or q is known, then so is the other. Hence there is only one degree of freedom.



```{r}
df <- length(c(AA_o, Aa_o, aa_o)) - length(c("A", "a"))
```

**Calculate p-value**

```{r}
pchisq(chi_sq,df, lower.tail = FALSE)
```

So we reject the null.

```{r}
#
raw_result <- chisq.test(c(AA_o, Aa_o, aa_o), p = c(AA_e, Aa_e, aa_e)/N)
chi_sq <- raw_result$statistic
pchisq(chi_sq,1,lower.tail = FALSE)
```

**Use built-in R function to calculate p-value**
```{r}
# not quite right
# uses df = 2 when it should use df = 1
chisq.test(c(AA_o, Aa_o, aa_o), p = c(AA_e, Aa_e, aa_e)/N)
```

::: callout-note

```{r}
chisq_statistic <- 1.48 
deg_freedom <- 1
df <- data.frame(x1 = chisq_statistic, y1 = 0, x2 = chisq_statistic, y2 = dchisq(chisq_statistic,deg_freedom))

pbase<- ggplot(data.frame(x=seq(0,10,0.1)), aes(x)) +
  geom_function(fun = dchisq, args=list(df = deg_freedom)) +
    theme_void()

p1 <- pbase +
    stat_function(fun = dchisq, 
                xlim = c(0,10),
                geom = "area",
                fill = fill_colour1,
                args = list(df=deg_freedom)) +
  annotate(geom = "text", x= 5, y = .15, label = "Total area = 1")


p2 <- pbase +
    stat_function(fun = dchisq, 
                xlim = c(chisq_statistic,10),
                geom = "area",
                fill = fill_colour1,
                args = list(df=deg_freedom)) +
    geom_segment(data = df, aes(x = x1, y = y1, xend = x2, yend = y2), linewidth = 0.2) +
  annotate(geom = "text", x= 5, y = .15, label = "p-value =0.224")
```

```{r}
#| label: fig-chi-square-plots
#| caption: Two plots of a chi-square distribution. 
#| layout-ncol: 2

p1
p2
```


:::

## Exercises

**Exercise 1**

Suppose you tossed a fair coin 100 times and got 45 heads and 55 tails.

-   Under a null hypothesis that the coin is fair, what would the expected numbers of heads and tails be?

You use R to do a chi-square test of that null hypothesis. Here is the code to do that and the output it would give:

```{r,echo=TRUE}
chisq.test(c(45,55),p=c(0.5,0.5)) # we could leave out the second argument here
```

-   What do you conclude?

-   How would you report the result?

**Exercise 2**

Suppose someone told you that the competence of scientists was linked to their astrological zodiac sign. I won't name all of these, but there are twelve of them: Pisces, Scorpio, Cancer etc. To test this hypothesis, you spend a lot of time on Primo and identify 240 scientists, currently active, that have each published at least five papers in high impact journals in the last year. All of these people, you presume, are successful scientists. You write to each of them and ask them their date of birth. Amazingly(!), all of them respond. You then assign each of them to a zodiac sign according to their birth date and get the following counts for each sign:

In this code chunk we have typed out the counts and collected them as a vector, using the function \``` c()` ``. we have saved this under the name `stars`.

```{r,echo = TRUE}
stars<-c(22,20,17,22,20,19,18,21,19,22,23,17)
```

-   What would be a suitable null hypothesis in this investigation?
-   What proportion of the total count would we expect for each star sign if this null were true?
-   The data meet the criteria required for use of a chi-square goodness of fit test. How can we tell?
-   Use the `chisq.test()` function to implement this test.
-   On the basis of the output of the test, do you reject the null hypothesis?
-   Report the result of the test in plain English.

### Solutions

**Solution 1**

The expectation is that half the outcomes would be heads and half would be tails.

The null hypothesis of this test is that heads and tails are equally likely, ie that the coin is fair. Under this null hypothesis the expected outcome is 50 heads and 50 tails. From the output of the R code we see that the p-value, the probability of getting an outcome as far or further from that, is 0.317. That is pretty high. Would you do anything if you knew that the probability of a bad (or worse) outcome was 0.317? In particular, this p-value is greater than 0.05, so we cannot reject the null hypothesis that the coin is fair. That is, even with a fair coin it is not at all unlikely that you would get head/tail numbers as different from 50/50 as 45/55 if you tossed the coin 100 times. That will happen about 1/3 of the time if you repeatedly do trials where you toss the coin 100 times.

To report this result, you might say something like

*From 100 coin tosses we got 45 heads and 55 tails. These counts are consistent at the 5% significance level with the coin being fair (chi-squared test, X-squared = 1, df = 1, p = 0.317).*

**Solution 2**

-   H0: There is no association between the astrological star sign of a researcher and their success in science (who knew?)
-   One twelfth for each sign ie a researcher is as likely to have one star sign as any other.
-   These are count data, there are at least five counts for every sign and the counts are independent - any individual researcher only contributes to one of the twelve counts.
-   Note that we do not need to include the second `p=...` argument in this case since the default presumption, that all proportions are equal, is true here.

```{r}
chisq.test(stars)
```

-   We see that the p-value is almost one so we emphatically do not reject the null hypothesis.
-   We find no evidence that star sign affects success in science (X-sq=2.29, df = 11, p=0.997)

Note the degrees of freedom that is reported: df = 11. The degrees of freedom is the number of independent pieces of information. Here, given that we know the total number of researchers, only eleven of the individual counts are independent. Once they are known, the twelfth can be calculated.

## Two-way Chi square analysis: test of independence

*Adapted from Chapter 5: Beckerman, Childs and Petchey: Getting Started with R*

-   For R code to implement this section, scroll down to the next section \*

A common scenario we have with count data is that there are two explanatory factors each with two or more levels that enable us to classify the data. This can happen when something is either true or not true, and a test for for this truth gives either a positive or a negative result. We might want to know if the test to determine truth was any better than flipping a coin: is there some association between what the truth is (eg I do or do not have a disease) and what the test says about that (testing positive or negative for the disease). In this example our data would be counts of people in each of four categories: have the disease / test positive, have the disease / test negative, do not have the disease / test positive and do not have the disease / test negative.

### Example - red and black ladybirds

We are going to analyse a scenario of this type to see if there is evidence for an association between two factors. Suppose we have some count data of ladybirds found in both an industrial and a rural location. In each location, some of the ladybirds are red and some are black. We would like to test for whether there is an association between the ladybird colour and its location. If there isn't then we would expect the proportion of black to red ladybirds to be roughly the same in both habitats. If there is, then we would expect the proportions to be different, meaning that knowing the habitat would tell us something about the likelihood of a ladybird found there being black or red. That is way of saying that the colour of the ladybirds would not be independent of the location.

Behind this the research purpose might be to investigate whether matching of morphological colour of the ladybirds to the prevalent colour of the environment confers an evolutionary advantage. If it does then we would expect there to be an association between morphological colour and environment so that the proportion of black to red ladybirds would be higher in a grimy industrial setting than in it would be in a shiny bright rural setting.

A **Chi-Square independence analysis** can be used to investigate this. This type of analysis is used when you have

* Count data - for example, how many red ladybirds in a rural setting, how many in an industrial setting, how many black ladydbirds in each of the settings?
* Enough count data - typically at least 5 individuals for each combination of the levels in question, which would be rural/red, rural/black, industrial/red and industrial/black in this case.
* Independent counts - each ladybird contributes to only one sub-total. For example, if it is red and found in a rural location, then it contributes to the count of red ladybirds found in a rural location, and not to any other sub-total, such as black ladybirds found in a rural location.
* No replicates - for ach combination of the levels of the fators, we have just one count.

All these are true for the ladybird study.

#### Hypotheses

What do you think a suitable hypothesis should be for this investigation, and what would the corresponding null hypothesis be?

-   The null hypotheses could be: **H~0~**: There is no association between habitat and ladybird colour. This means that whatever the proportion is of black to red ladybirds, it is the same in both habitats.\
-   The alternate hypothesis could be: **H1**: There is an association between habitat and ladybird colour. That is, the proportion of red to black differs between the two habitats.

```{r,message=FALSE, echo = FALSE}
# Load packages we need
library(tidyverse)
library(here)
library(cowplot) # this makes your plots look nicer
library(kableExtra)
theme_set(theme_cowplot()) # this sets the cowplot theme to be the default theme for any plots we make..
```

```{r, echo = FALSE}
# Import the data
filepath<-here("data","ladybirds_morph_colour.csv")
lady<-read_csv(filepath)
#glimpse(lady)
```

#### The data

The data consist of counts of the number of ladybirds of each colour that were observed in 5 rural sites and 5 industrial sites. These data are in tidy form, with one variable per column. There are 20 rows, with each row containing the count of either red or black ladybirds found at a given site.

```{r, echo = FALSE}
head(lady,20)
```

The total counts for red and black ladybirds observed in industrial and rural settings are shown below:

```{r, echo = FALSE}
# Calculate the totals of each colour in each habitat.
totals<- lady |>
  group_by(Habitat,morph_colour) |>
  summarise (total.number = sum(number))
# totals |>
#   kbl() |>
#   kable_styling(full_width=FALSE)
totals
```

#### Plot the data.

From these totals we can create a bar chart:

```{r,echo = FALSE, eval=TRUE}
# plot the data, with sensible colours
totals |>
  ggplot(aes(x = Habitat,y = total.number,fill=morph_colour))+
  geom_col(position='dodge') +
  labs(x="Habitat",
       y="Count",
       fill= "Colour") +
  scale_fill_manual(values=c(black='#312626',red='#da1717')) + # this line manually sets the fill colours for us
  theme(legend.position="none")

```

#### Interpret the graph before we do any 'stats'

Look at the plot - does it look as though the proportion of black to red ladybirds is the same in the two habitats? Do you expect to retain or to reject the null hypothesis, which says that there is no association between habitat and ladybird colour, and hence that the proportions are the same?

A chi-square test of independence will enable us to determine how likely it is that we would have got proportions of black to red as different as or more different than they actually are if the null hypothesis were true.

#### The Chi-square test

To do the chi square test, it helps to set out our count data as a 2 x 2 table of total counts:

```{r, echo = FALSE}
lady.mat<-xtabs(number~Habitat + morph_colour, data=lady)
lady.mat
```

This kind of table is sometimes called a **contingency table**.

When we give these numbers to some statistical software such as R and ask it to carry out a 'chi-square test' it will use the data to calculate a 'test statistic' $X^2$ by comparing the actual counts of the ladybirds in the table above with their expected counts under the null hypothesis. The further the actual counts are from their expected values, on the whole, the bigger this test statistic will be. For the gory (they are not that gory!) details on how this is done, see section 4 below but do note that, while these are interesting, if you find that kind of thing interesting, as I do, you do not need to be familiar with them to be able to apply a chi-square test. What you do need to know is when it is OK to use one, and when it is not, as is true for any statistical test.

We'll turn to that issue now:

Providing a number of conditions are met by the data (principally, that they are count data, that all the cell values are greater than or equal to about five and that they are all independent ie any ladybird contributes to the count of only one cell), this test statistic $X^2$ has a so-called 'chi-squared' distribution. This is a known mathematical distribution, which makes it possible to calculate the probability that the statistic would be as big as it is, or bigger, if the null hypothesis were true. We call this probability the *p*-value.

This is generally how statistical tests work. They take your data and use it in a carefully chosen way to calculate some number that in general is called a *test statistic* but which is referred to by different names when calculated for particular tests. How it is calculated depends on the test and these days we never have to manually do the calculations ourselves. That's taken care of by software like R. Providing the data meet certain criteria, the statistic will typically have a known probability distribution. This means that the probability that it will exceed a given value if the null hypothesis is true can be calculated. This probability is the *p*-value. If the *p*-value is very small, and by that we typically mean less than 0.05 or 0.01, then we can reject the null hypothesis.

When we run a chi-square test in R on the data in the table above it gives us this as output:

```{r}
chisq.test(lady.mat)
```

#### Conclusion

Study the output of the chi-square test. Note that you are given a test-statistic (here called Chi-squared/X-squared) and a number of degrees of freedom (*df*) (in some tests you are given more than one of these). This is the number of independent pieces of information used to calculate the test statistic. Lastly, you are a given a *p*-value. This is the probability that you would have got a chi-squared value as big or bigger than the one you got *if* the null hypothesis were true. Here the null hypothesis is that there is no association between ladybird colour and location. Put another way, it is, roughly speaking the probability of getting the data you actually got if the null hypothesis were true.

Here, the p-value is much less than 0.05, so we can safely *reject* the null hypothesis. The ladybird colour does not appear to be independent of the setting.

An appropriate way to report these data would be:

'Ladybird colour morphs are not equally common in the two habitats (Chi-sq =19.3, df = 1, p\<0.001)'

#### Yates continuity correction

This is mentioned is the output of the test. What does it mean? It adjusts for the fact that our data are discrete and the chi-square distribution that we are using to calculate the *p*-values is continuous. That's it.