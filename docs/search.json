[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CORN276-RMGIS",
    "section": "",
    "text": "Preface\nThis will develop into your course notes for Research Methods and GIS for Zoology.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "visualising_data.html",
    "href": "visualising_data.html",
    "title": "1  Visualising data",
    "section": "",
    "text": "1.1 Summarise the data\nWhen we have got our data safely tucked into a spreadsheet. Now we need to tease out of it the answers to our question(s) and to decide whether we have evidence enough to reject our null hypotheses, or not, in which case we will fail to reject them.\nLet’s take the example of the Palmer penguins dataset. This set contains measurements of bill depth, bill length, flipper length and body mass of males and females of three species of penguins: Adelie, Chinstrap and Gentoo observed on any one of three islands in the Palmer Archipelago, Antarctica.\nLet’s consider only the females and ask the question:\nQuestion: Is there any difference in body weight between the females of the three species?\nfrom which we can generate a hypothesis:\nHypothesis: There is a difference in body weight between females ofthe three species.\nNull hypothesis: There is no difference in body weight between females of the three species.\nand hence a prediction of what we will find if the hypothesis is true:\nPrediction if the hypothesis is true: The females of at least one species will have a different average body mass than those of at least one other species.\nThe first thing we can do to investigate our hypotheses is to summarise the data. More often than not this means caclulating three things for each sample - the sample sizes, the mean values and the standard errors of those means.\nSpecies\nN\nMean body mass (g)\nStandard error (g)\n\n\n\n\nChinstrap\n34\n3527\n48.9\n\n\nGentoo\n58\n4680\n37.0\n\n\nAdelie\n73\n3369\n31.5\nThe errors calculated here are standard errors of the mean. We use these because we want to get an idea, from our samples, of how plausible it is that the population means differ from each other. These population means could plausibly lie anywhere in the range that is our sample means plus or minus two of these standard errors.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Visualising data</span>"
    ]
  },
  {
    "objectID": "visualising_data.html#summarise-the-data",
    "href": "visualising_data.html#summarise-the-data",
    "title": "1  Visualising data",
    "section": "",
    "text": "Types of error bar\n\n\n\nstandard deviations: These tell us about the spread of values in a sample or a population. They do not systematically get bigger or smaller as the sample size increases. The standard deviation of a sample can be used as an estimate of the standard deviation of the population. We use standard deviations for descriptive purposes\nstandard errors of the mean These are used to indicate how precisely a sample mean estimates the true population mean. They are used for inferential purposes, whereby we try to infer from the sample mean the range of values in which the true population mean might be. Assuming normally distributed values, it would be very surprising if the true population means were more than two standard errors away from the sample means.\nStandard errors are calculated from the standard deviations (SD) of the sample using the formula \\(\\text{SE}=\\frac{\\text{SD}}{\\sqrt{n}}\\) where n is the sample size. This means that standard errors do get systematically smaller, the larger the sample. The larger the sample, the closer the sample mean is likely to be to the true population mean. Who knew?\nconfidence intervals These are also inferential tools. They tell us the range of values within which the true mean might plausibly lie, at some level of confidence, usually 95%.\nIf you include error bars in a plot you can use any of these three errors, depending on the story you want to tell. Whichever, just must state in the figure caption which of them you have used. Failing to do this can seriously mislead the reader, since they can be of very different magnitudes.\n\n\n\n\nDoes it look as though there is evidence form the data for a difference between Adelie and Chinstrop penguins?\nWhat about the Gentoos compared to either of the other two?\nDo we have evidence to reject the null hypothesis. (Clue: yes we do!)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Visualising data</span>"
    ]
  },
  {
    "objectID": "visualising_data.html#plot-the-data",
    "href": "visualising_data.html#plot-the-data",
    "title": "1  Visualising data",
    "section": "1.2 Plot the data",
    "text": "1.2 Plot the data\nAfter summarising the data, then ext thing we nearly always do in deciding what the data is telling us is to plot the data. We have several choices of how to do so and each has its pros and cons. Let’s run through a few of them.\n\n1.2.1 Bar charts\n\n\n\n\n\n\n\n\n\n\n\n(a) Terrible!\n\n\n\n\n\n\n\n\n\n\n\n(b) Standard errors added\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Sample sizes added\n\n\n\n\n\n\n\n\n\n\n\n(d) Redundant colours removed\n\n\n\n\n\n\n\nFigure 1.1: Bar charts, from worst to best\n\n\n\n\n\n1.2.2 Histograms\nIn histograms the range of a variable is split into bis of. certain width, then the number of observations that fall within each bin is displayed.\nThey can be used to inspect a data set, even one with multiple categories, as with the penguin data. Unlike bar charts they do show the distribution of the dataset, including its central value, spread and symmetry, or lack thereof.\nThey do need care however in choice of the width of the bins. Make these too narrow and the histograms can look gappy, with too much scatter introduced by there not being many observations in each bin. Make the bins too wide and much of the detail of the distribution is lost. You need to find, approximately, the ‘Goldilocks’ width, one that is just right. Sometimes, though, you choose a binwidth that has meaning to you and the reader, such as widths of 1 m/s if you were doing a histogram of a set of wind speed measurements.\nWe illustrate that issue in Figure 1.2 where we show histograms of the body masses of the Adelie females in the sample, one with bins that are too narrow (50g), one where they are about right (100g) and one where they are too wiede (200g)\n\n\n\n\n\n\n\n\n\n\n\n(a) bins too narrow\n\n\n\n\n\n\n\n\n\n\n\n(b) Bin width about right\n\n\n\n\n\n\n\n\n\n\n\n(c) Bins too wide\n\n\n\n\n\n\n\nFigure 1.2: Histograms of different bin width\n\n\n\nAs for our hypotheses, if we plot histograms of the body masses of the females, one for each species, and put display them in a column, one on top of the other, we get some insight as to whether we are likely to reject our null hypothesis, or fail to reject it.\n\n\n\n\n\n\n\n\n\nUnlike the bar charts, histograms also tell us about the shape and widths of the distributions of the three data sets. When we do actually use a statistics test to make a decision about our hypotheses, these features of the data will be very important in helping us decide which test is the right one.\n\n\n1.2.3 Box plots\nA very useful plot type for help in answering difference questions is the box and whisker plot, often just called a box plot. We normally use them where we have continuous data spread across one or mre categorical variables.\nHere is a box and whisker plot of the female penguins body mass data, with one box for each species. Note that we have used the same colour for each box. We already know which species is which, so to use different colours would imply an additional difference that isn’t there. It would confuse the reader.\n\n\n\n\n\n\n\n\nFigure 1.3: Anatomy of a box and whisker plot. Here the data are symmetrically distributed\n\n\n\n\n\nIn box and whisker plots, or box plots for short, we are shown a summary of the distribution of each data set and its central location.\nConsider Figure 1.3.\nEach box shows:\n\nthe 75th percentile of the data: this is the top of the box\nthe 50th percentile of the data ie the median: this is the thick black line somewhere across the box. If the dataset is symmetric, this line is in the middle of the box.\nthe 25th percentile of the data: this is the bottom of the box\nthe interquartile range ie rnage that contains the middle 50% of the data. This is the range of values between the top of the box and the bottom.\n\nthe whiskers show:\n\nthe range of the rest of the data that goes beyond the interquartile range - ie how far uop and down the range top and bottom quartiles spread.\n\nany outlier(s) are shown by individual dots. Outliers are, more or less, jsut what the name says, daa values that are atypical of the rest of the data.\nA box plot can also show:\n\nwhether there is a clear difference between the spread of values of the different catagories. Do the boxes overlap or are they clearly separated in the vertical direction? This helps us decide whether or not to reject a null hypothesis about there being no difference.\n\nIn ?fig-box-plots we can see that the body masses of Gentoo penguins are clearly greater than those of the other two species, but that there is no clear indication from these data that there is any difference between those two.\n\nwhether the distributions of the individual points are of about the same width and if they are approximately symmetric. If they are, then perhaps the points are normally distributed about their means and have similar variances. In that case it may be possible to use so-called parametric tests for difference such as t-tests and ANOVAs of one kind or another. If not, then we may have to use their less powerful non-parametric equivalents such as Mann-Whitney tests or Kruskal-Wallis tests.\n\nWe see in Figure 1.3 that all the boxes are of about the same width, meaning the spread of values (the variance) is about the same for each species and that all the plots are more or less symmetric, wit th emedians more or less in the middle. There is only one outlier which isn’t too far out, and all the medians are more or less in the centre of the boxes, as we would expect fo a symmetric distribution. This means that the data pluasibly might be normally distributed. There is a better type of plot for determing normality, the quantile-quantile plot, but this quick check for normality from a box plot is a useful thing to be able to do.\nFor contrast, we show in Figure 1.4 what box plots can look like when you have data that really isn’t normally distributed. You might get data like this if you were at the zoo and counting how many times an animal exhibited this or that behavioural trait in successive 20 minute blocks of time. In most blocks they either wouldn’t exhibit the trait at all or maybe they would but only once, occasionally twice. Very occasionally they would have a splurge of activity and you’d get a high count.\n\n\n\n\n\n\n\n\nFigure 1.4\n\n\n\n\n\n\n\n1.2.4 Improving the box plot\nIn its basic form the box plot does not show us the sample size or the internal detail of the sample distribution, for example whether it is bimodal or not.\nWe can fix that in at least a couple of ways as shown in Figure 1.5. We can add the sample sizes as annotations as we did with the bar charts, and/or we can the data points themselves, with a bit of sideways ‘jitter’ so that they don’t all lie on top of each other. This can be effective if the sample size is not too large.\n\n\n\n\n\n\n\n\n\n\n\n(a) Sample sizes added as annotations.\n\n\n\n\n\n\n\n\n\n\n\n(b) Points added with some sideways jitter\n\n\n\n\n\n\n\nFigure 1.5: Improved box plots",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Visualising data</span>"
    ]
  },
  {
    "objectID": "counts.html",
    "href": "counts.html",
    "title": "2  Chi-squared analysis of count data",
    "section": "",
    "text": "2.1 Chi-square goodness of fit test\nA chi-square analysis is used when\nWhat we do is compare the counts we got to some expected value according either to chance or to some prior theory.\nFor example:\nIn a chi-square ‘goodness of fit’ test, we are testing data where we have a number of counts for each of two or more possible outcomes of some procedure (heads/tails, dice scores, pea colour etc). We have an idea of how these counts should be distributed under some null hypothesis (the coin is fair, the dice is fair, genetic inheritance works in this or that way etc). The chi-square goodness of fit test tests how likely it is we would have got the counts we actually got if that null hypothesis were correct. We are testing how well our actual counts ‘fit’ the expected values.\nIn a typical software implementation of the test, such as in R, we give it the counts we actually got for each possible outcome and also the expected proportion for each outcome. The test then gives us a p-value, a probability, for how likely it is that we would have got the counts we actually got, or counts even further from the null hypothesis, if that null hypothesis were correct. If this p-value is too small, and by that we usually mean less than 0.05, then we reject the null hypothesis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chi-squared analysis of count data</span>"
    ]
  },
  {
    "objectID": "counts.html#chi-square-goodness-of-fit-test",
    "href": "counts.html#chi-square-goodness-of-fit-test",
    "title": "2  Chi-squared analysis of count data",
    "section": "",
    "text": "2.1.1 Example: Mendelian Genetics\nIf the basic idea of Mendelian inheritance with independent assortment involving a single gene is correct, then we would expect that if we crossed a large number of pea plants that were heterozygous for yellow and green pea colour, as in the F1 generation shown in Figure 2.1 with yellow being dominant, then the offspring in the F2 generation would in the long run be expected to have yellow:green peas in the ratio 3:1 (plants with genotypes YY, Yy, yY would all have yellow seeds and only those with yy would have green seeds). In practice, if the inheritance were according to the simplest type of Mendelian inheritance (ie involving just one gene, amongst other things) we would probably get yellow:green offspring in a ratio that was approximately but not exactly 3:1. How far from 3:1 would the ratio need to be before we would justified in claiming that the outcome was inconsistent with the Mendelian prediction?\n\n\n\n\n\n\n\n\nFigure 2.1: An outline of Mendel’s green:yellow pea crossing study. In the F1 generation there would necessarily be 100% yellow plants with genotype Yy. In the F2 generation the ratio 3:1 yellow:green is what is expected if random Mendelian inheritance is the underlying mechanism. In reality we would probably not see excatly that ratio. A chi-square goodness of fit test tells us how likely it is we would get the ratio we got, or a more extreme ratio, if Mendelian inheritance were correct. Source: Khan Academy\n\n\n\n\n\nSuppose we have crossed pea plants that were all heterozygous for yellow/green pea colour. In the F2 generation we get 176 offspring, of which 125 are yellow and 51 are green. These are the observed counts of yellow and green pea plants. The expected counts of yellow and green are found by simply dividing the total count of offspring, 176, in the ratio 3:1, giving us an expected 132 yellow pea plants and an expected 44 green pea plants in the offspring F2 generation.\nThe data here are raw counts, and an individual pea plant offspring contributes either to the yellow count or to the green count, but not to both.\nDoing the chi-square test manually\nYou would not normally do this, you would use software such as R, but for learning purposes let us go as far as we can in implementing a chi-square test on this data ourselves just to see the process behind it, then we can see how easy it is to do the test in R.\nWhat we need to do is to calculate from our data a number that tells us how likely is it that we would have got totals for yellow and green pea plants as far or further from the expected 3:1 ratio as we did, if the null hypothesis of Mendelian inheritance were correct.\nThat is the very definition of a p-value! So that is what we need to calculate, a p-value.\nIt turns out that this p-value an be calculated from a number derived from the data that we call the chi-square statistic. This number is defined in such a way that the further your actual counts are from thier expected values, the bigger it is.\nIt is calculated by looking at the squared difference, for each count, between the observed value and the expected value. The squared thing is because we don’t care if the observed value is less than or more than the expected value. It is by how much that matters.\nHere is the expression for the chi-square statistic:\n\\[\n\\begin{align}\n\\chi^2 &= \\sum_{i=\\text{Y,G}}\\frac{(O_i-E_i)^2}{E_i}\\\\ &=\\frac{(O_\\text{Y}-E_\\text{Y})^2}{E_\\text{Y}} + \\frac{(O_\\text{G}-E_\\text{G})^2}{E_\\text{G}}\n\\end{align}\n\\] The first line is just a more compact way of witing the second line, where the \\(\\sum\\) symbol means ‘sum over’ a yellow peas term (Y) and a green peas term (G), as laid out in the second line. \\(O_\\text{Y}\\) and \\(O_\\text{G}\\) mean the observed numbers of yellow and green pea plants respectively, while \\(E_\\text{Y}\\) and \\(E_\\text{G}\\) mean the expected numbers of each.\nDefined in this way, the chi-square statistic \\(\\chi^2\\)is a number that will always be positive (because it is the sum of squared terms, and they are always positive, divided by an expected number, which can also only be positive) and will be bigger the further from the expected values our observed values turn out to be.\nIt is also a number that will vary each time you repeat the study because while the expected values \\(E_i\\) are fixed, the observed values \\(O_i\\) will vary from one occasion to the next. In fact, if you were to repeat the study many times and each time calculate the chi-sqare statistic you would find that it follows one of a known family of distributions, the so-called (who would have thought it?) chi-square distributions, provided each count is greater than about five.\nTo determine which one among them is followed by our own chi-squared statistic we need to know one more thing, the so-called degrees of freedom. This is a term that crops up often when using statistical tests. Roughly speaking, it refers to the number of independent pieces of information that are used in arriving at a result, given whatever constraints surround the problem. In our case, the constraint was that there were 176 pea plants in total in the F2 generation. That meant that only one of the sub-totals for each of the colours could be freely chosen. Once it was known the other could be determined as the difference between it and the total: if there are 176 plants in total and 125 of them are yellow, then the green total has to be 176 - 125 = 51. So, in our case the degrees of freedom is one.\nFinally, knowing the chi-square statistic for our data, and knowing the degrees of freedom for our design, and thus knowing which chi-squae distribution is followed by our statistic, we can calculate the probability of getting a chi-squared value as great or greater than the one we got. This in turn means (because it is the same thing in the end) that we can calculate the probability of getting data as far or further from the the expected values as the numbers we got - the magic p-value. We get software such as R to do this last bit for us.\n\n\n\n\n\n\nChi-square distributions and the p-value\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.2\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.3\n\n\n\n\n\n\n\n\nFinally, on that basis we can either reject or fail to reject the null hypothesis.\nLet’s have a go:\nFirst we calculate our chi-squared statistic:\n\\[\n\\begin{align}\n\\chi^2 &=\\frac{(O_\\text{Y}-E_\\text{Y})^2}{E_\\text{Y}} + \\frac{(O_\\text{G}-E_\\text{G})^2}{E_\\text{G}}\\\\\n&=\\frac{(125-132)^2}{132} + \\frac{(51-44)^2}{44}\\\\\n&=1.48\n\\end{align}\n\\]\n\n\n[1] 0.224\n\n\nDoing the chi-square test in R\nWhat we do in R is use the chisq.test() function to see how likely it is we would have got counts of 125 and 51 if the null hypothesis, with its expected counts in the ratio 3:1, were true.\nWe do it like this:\nchisq.test(c(125,51),p=c(0.75,0.25))\nThere are two arguments. The first is the counts we got, which we enter as a ‘vector’ c(z,y,....), so we write c(130,46). The second is a vector of the proportions we expect for the two counts, where these proportions should add up to one. So for our expected 3:1 ratio we enter c(0.75,0.25).\nLet’s do it: type the above function into the console window (bottom left). You will get an output something like this:\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  c(125, 51)\nX-squared = 1, df = 1, p-value = 0.2\n\n\nThis output is typical of tests done in R. We get the ‘test statistic’ whose name varies depending on the test. Here it is called X-squared, pronounced chi-squared. This is a number that the test calculates, based on the data you have given it. For the most part, we don’t need to worry about how it does that. Then there is the p-value, which is the probability of getting this test statistic if the null hypothesis were true.\nIn this case, we see that the p-value is 0.223, which is large. We could very plausibly have got yellow:green numbers of 125 and 51 if the null hypothesis were true, so we cannot reject that null hypothesis. In other words, our data are consistent at the 5% significance level with the predictions of simple Mendelian inheritance.\nReporting the result in English\nIn English, we might report this result as:\nWe found counts of 125 yellow plants and 51 green plants, which are consistent at the 5% significance level with the predictions of Mendelian inheritance (chi-squared test, X-squared = 1.48, df = 1, p=0.223).\nNote that we do not say we have proved Mendelian inheritance to be correct. We haven’t. We never prove things in science. We haven’t said anything about the truth of the null hypothesis. All we can say is whether our data are or are not consistent with the null hypothesis. In this case they are. We then report the test we used and the values of the test statistic and p-value. Other tests might give you other details to report too.\n\n\n2.1.2 Testing if Hardy Weinberg Equilibrium is satisfied\nSuppose we have a population of people in which there is a gene that has two alleles A and a, where A is dominant. Suppose that being homozygous in the recessive allele a means that the individual is affected by sickle cell anemia. Being heterozygous Aa means that the individual is not affected but is a carrier and may pass the a allele on to their progeny. Those who are homozygous in the dominant allele A are unaffected.\nObserved Frequencies\nSuppose in a population of \\(N=1100\\) people the observed numbers of each genotype are as follows:\n\\[\n\\begin{align}\n\\text{AA}_\\text{O} &= 756\\\\\n\\text{Aa}_\\text{O} &= 200\\\\\n\\text{aa}_\\text{O} &= 144\\\\\n\\end{align}\n\\]\nwhere the subscript letter \\(O\\) denotes ‘Observed’\nCalculate allele frequencies\nEach person in the population carries two copies of the gene so the total number of alleles is \\(2N\\). We use \\(p\\) and \\(q\\) to denote the proportion of these that are \\(A\\) and \\(a\\) alleles respectively.\nEach person who is homozygous in \\(\\text{A}\\) carries two copies of the \\(A\\) allele while each heterozygous person carries one. \\(p\\), the proportion of all alleles that are \\(A\\), will be the number of \\(A\\) alleles in the population divided by the total number of alleles and will will be given by\n\\[\n\\begin{align}\np &= \\frac{2 \\times \\text{AA}_\\text{O} + \\text{Aa}_\\text{O} }{2N}\\\\\n&=\\frac{2\\times 756 + 200}{2\\times 1100}\\\\\n&=\\frac{1712}{2200}\\\\\n&=0.778\n\\end{align}\n\\]\nSimilarly, \\(q\\), the proportion of all alleles that are \\(a\\), will be the number of \\(a\\) alleles in the population divided by the total number of alleles and will will be given by\n\\[\n\\begin{align}\nq &= \\frac{2 \\times \\text{aa}_\\text{O} + \\text{Aa}_\\text{O} }{2N}\\\\\n&=\\frac{2\\times 144 + 200}{2\\times 1100}\\\\\n&=\\frac{488}{2200}\\\\\n&=0.222\n\\end{align}\n\\]\n\n\n[1] 1\n\n\nExpected under HWE\nUnder Hardy-Weinberg equilibrium, a key assumption is that there is random mating among individuals in the population. This means that the probability of an individual having any of the three possible genotypes is the product of the frequencies of the two alleles present for that genotype.\nHence, under Hardy-Weinberg individual, we would expect the following genotype frequencies:\n\n\n\nGenotype\nExpected Frequency\n\n\n\n\nAA\n\\(p^2\\)\n\n\nAa\n\\(2pq\\)\n\n\naa\n\\(q^2\\)\n\n\n\nThe numbers we would expect for each genotype, if Hardy-Weinberg equilibrium held would be these frequencies multipled by the total populations:\n\n\n\n\n\n\n\n\nGenotype\nExpected Frequency\nExpected Number\n\n\n\n\nAA\n\\(p^2\\)\n\\(p^2 \\times N = 0.788^2 \\times 1100 = 666\\)\n\n\nAa\n\\(2pq\\)\n\\(2pq \\times N = 2\\times 0.788\\times 0.222 \\times 1100 = 380\\)\n\n\naa\n\\(q^2\\)\n\\(q^2 \\times N = 0.222^2 \\times 1100 = 54\\)\n\n\n\nCalculate Chi-squared statistic\n\\[\n\\begin{align}\n\\chi^2 &= \\sum_{i=1}^3\\frac{(O_i-E_i)^2}{E_i}\\\\\n&=\\frac{(756-666)^2}{666} +\\frac{(200-380)^2}{380} + \\frac{(144-54)^2}{54}\\\\\n&=246.5\n\\end{align}\n\\]\nWe find that the chi-sqaure value is 246.457, which is very large. Remember that, the larger the chi-square value, the the further our observed values must be from the expected values, and thus, intuitibely, the more likely it must be that we will reject the null hypothesis.\nCalculate degrees of freedom\nThis is the number of independent pieces of information used in calculating the test statistics \\(\\chi^2\\). In problems like this it turns out to. be equal to the number of gneotypes minus the number of alleles, so in this case the answer is 3 - 2 = 1. The underlying reason for this is that the expected genotype numbers are determined by the allele frequencies p and q. Since these must add up to one, that means that if either p or q is known, then so is the other. Hence there is only one degree of freedom.\nCalculate p-value\nThe p-value will be the area under the chi-square distribution for one degree of freedom (or whatever that might be for another problem) to the right of the chi-square statistic.\nThus, the p-value is the probability of getting a chi-square statistic as large or larger than the one we got, if the null hypothesis were true. This is the same thing as saying that the p-value is the probability of getting observed values as far or further as ours were from the epxevted value, if the null were true.\nWe get softwae such as R to calculate this for us. In this R would tell us that the p-value is really tiny, much less than 0.05.\n\n\n[1] 1.54e-55\n\n\nSo we reject the null.\n\n\nX-squared \n 1.54e-55 \n\n\nUse built-in R function to calculate p-value\nHang on! Do I need to go through all these calculations every time I want to carry out a chi-square test?\nNo! You get software to do it. Her is how we would do it in R and what it would tell us, in this case:\n\n\nX-squared \n      246 \n\n\n\n\n[1] 1.93e-55\n\n\nThis is R’s way of saying that the p-value is more or less zero.\nConclusion The p-value is very small indeed, much less than 0.05. Hence we reject the null hypothesis that the population is in Hardy-Weinberg equlibrium.\n\n\n2.1.3 Exercises\nExercise 1\nSuppose you tossed a fair coin 100 times and got 45 heads and 55 tails.\n\nUnder a null hypothesis that the coin is fair, what would the expected numbers of heads and tails be?\n\nYou use R to do a chi-square test of that null hypothesis. Here is the code to do that and the output it would give:\n\nchisq.test(c(45,55),p=c(0.5,0.5)) # we could leave out the second argument here\n\n\n    Chi-squared test for given probabilities\n\ndata:  c(45, 55)\nX-squared = 1, df = 1, p-value = 0.3\n\n\n\nWhat do you conclude?\nHow would you report the result?\n\nExercise 2\nSuppose someone told you that the competence of scientists was linked to their astrological zodiac sign. I won’t name all of these, but there are twelve of them: Pisces, Scorpio, Cancer etc. To test this hypothesis, you spend a lot of time on Primo and identify 240 scientists, currently active, that have each published at least five papers in high impact journals in the last year. All of these people, you presume, are successful scientists. You write to each of them and ask them their date of birth. Amazingly(!), all of them respond. You then assign each of them to a zodiac sign according to their birth date and get the following counts for each sign:\nIn this code chunk we have typed out the counts and collected them as a vector, using the function `c()`. we have saved this under the name stars.\n\nstars&lt;-c(22,20,17,22,20,19,18,21,19,22,23,17)\n\n\nWhat would be a suitable null hypothesis in this investigation?\nWhat proportion of the total count would we expect for each star sign if this null were true?\nThe data meet the criteria required for use of a chi-square goodness of fit test. How can we tell?\nUse the chisq.test() function to implement this test.\nOn the basis of the output of the test, do you reject the null hypothesis?\nReport the result of the test in plain English.\n\n\n\n2.1.4 Solutions\nSolution 1\nThe expectation is that half the outcomes would be heads and half would be tails.\nThe null hypothesis of this test is that heads and tails are equally likely, ie that the coin is fair. Under this null hypothesis the expected outcome is 50 heads and 50 tails. From the output of the R code we see that the p-value, the probability of getting an outcome as far or further from that, is 0.317. That is pretty high. Would you do anything if you knew that the probability of a bad (or worse) outcome was 0.317? In particular, this p-value is greater than 0.05, so we cannot reject the null hypothesis that the coin is fair. That is, even with a fair coin it is not at all unlikely that you would get head/tail numbers as different from 50/50 as 45/55 if you tossed the coin 100 times. That will happen about 1/3 of the time if you repeatedly do trials where you toss the coin 100 times.\nTo report this result, you might say something like\nFrom 100 coin tosses we got 45 heads and 55 tails. These counts are consistent at the 5% significance level with the coin being fair (chi-squared test, X-squared = 1, df = 1, p = 0.317).\nSolution 2\n\nH0: There is no association between the astrological star sign of a researcher and their success in science (who knew?)\nOne twelfth for each sign ie a researcher is as likely to have one star sign as any other.\nThese are count data, there are at least five counts for every sign and the counts are independent - any individual researcher only contributes to one of the twelve counts.\nNote that we do not need to include the second p=... argument in this case since the default presumption, that all proportions are equal, is true here.\n\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  stars\nX-squared = 2, df = 11, p-value = 1\n\n\n\nWe see that the p-value is almost one so we emphatically do not reject the null hypothesis.\nWe find no evidence that star sign affects success in science (X-sq=2.29, df = 11, p=0.997)\n\nNote the degrees of freedom that is reported: df = 11. The degrees of freedom is the number of independent pieces of information. Here, given that we know the total number of researchers, only eleven of the individual counts are independent. Once they are known, the twelfth can be calculated.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chi-squared analysis of count data</span>"
    ]
  },
  {
    "objectID": "counts.html#two-way-chi-square-analysis-test-of-independence",
    "href": "counts.html#two-way-chi-square-analysis-test-of-independence",
    "title": "2  Chi-squared analysis of count data",
    "section": "2.2 Two-way Chi square analysis: test of independence",
    "text": "2.2 Two-way Chi square analysis: test of independence\nAdapted from Chapter 5: Beckerman, Childs and Petchey: Getting Started with R\n\nFor R code to implement this section, scroll down to the next section *\n\nA common scenario we have with count data is that there are two explanatory factors each with two or more levels that enable us to classify the data. This can happen when something is either true or not true, and a test for for this truth gives either a positive or a negative result. We might want to know if the test to determine truth was any better than flipping a coin: is there some association between what the truth is (eg I do or do not have a disease) and what the test says about that (testing positive or negative for the disease). In this example our data would be counts of people in each of four categories: have the disease / test positive, have the disease / test negative, do not have the disease / test positive and do not have the disease / test negative.\n\n2.2.1 Example - red and black ladybirds\nWe are going to analyse a scenario of this type to see if there is evidence for an association between two factors. Suppose we have some count data of ladybirds found in both an industrial and a rural location. In each location, some of the ladybirds are red and some are black. We would like to test for whether there is an association between the ladybird colour and its location. If there isn’t then we would expect the proportion of black to red ladybirds to be roughly the same in both habitats. If there is, then we would expect the proportions to be different, meaning that knowing the habitat would tell us something about the likelihood of a ladybird found there being black or red. That is way of saying that the colour of the ladybirds would not be independent of the location.\nBehind this the research purpose might be to investigate whether matching of morphological colour of the ladybirds to the prevalent colour of the environment confers an evolutionary advantage. If it does then we would expect there to be an association between morphological colour and environment so that the proportion of black to red ladybirds would be higher in a grimy industrial setting than in it would be in a shiny bright rural setting.\nA Chi-Square independence analysis can be used to investigate this. This type of analysis is used when you have\n\nCount data - for example, how many red ladybirds in a rural setting, how many in an industrial setting, how many black ladydbirds in each of the settings?\nEnough count data - typically at least 5 individuals for each combination of the levels in question, which would be rural/red, rural/black, industrial/red and industrial/black in this case.\nIndependent counts - each ladybird contributes to only one sub-total. For example, if it is red and found in a rural location, then it contributes to the count of red ladybirds found in a rural location, and not to any other sub-total, such as black ladybirds found in a rural location.\nNo replicates - for ach combination of the levels of the fators, we have just one count.\n\nAll these are true for the ladybird study.\nHypotheses\nWhat do you think a suitable hypothesis should be for this investigation, and what would the corresponding null hypothesis be?\n\nThe null hypotheses could be: H0: There is no association between habitat and ladybird colour. This means that whatever the proportion is of black to red ladybirds, it is the same in both habitats.\n\nThe alternate hypothesis could be: H1: There is an association between habitat and ladybird colour. That is, the proportion of red to black differs between the two habitats.\n\nThe data\nThe data consist of counts of the number of ladybirds of each colour that were observed in 5 rural sites and 5 industrial sites. These data are in tidy form, with one variable per column. There are 20 rows, with each row containing the count of either red or black ladybirds found at a given site.\n\n\n# A tibble: 20 × 4\n  Habitat Site  morph_colour number\n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;\n1 Rural   R1    black            10\n2 Rural   R2    black             3\n3 Rural   R3    black             4\n4 Rural   R4    black             7\n5 Rural   R5    black             6\n6 Rural   R1    red              15\n# ℹ 14 more rows\n\n\nThe total counts for red and black ladybirds observed in industrial and rural settings are shown below:\n\n\n# A tibble: 4 × 3\n# Groups:   Habitat [2]\n  Habitat    morph_colour total.number\n  &lt;chr&gt;      &lt;chr&gt;               &lt;dbl&gt;\n1 Industrial black                 115\n2 Industrial red                    85\n3 Rural      black                  30\n4 Rural      red                    70\n\n\nPlot the data.\nFrom these totals we can create a bar chart:\n\n\n\n\n\n\n\n\n\nInterpret the graph before we do any ‘stats’\nLook at the plot - does it look as though the proportion of black to red ladybirds is the same in the two habitats? Do you expect to retain or to reject the null hypothesis, which says that there is no association between habitat and ladybird colour, and hence that the proportions are the same?\nA chi-square test of independence will enable us to determine how likely it is that we would have got proportions of black to red as different as or more different than they actually are if the null hypothesis were true.\nThe Chi-square test\nTo do the chi square test, it helps to set out our count data as a 2 x 2 table of total counts:\n\n\n            morph_colour\nHabitat      black red\n  Industrial   115  85\n  Rural         30  70\n\n\nThis kind of table is sometimes called a contingency table.\nWhen we give these numbers to some statistical software such as R and ask it to carry out a ‘chi-square test’ it will use the data to calculate a ‘test statistic’ \\(X^2\\) by comparing the actual counts of the ladybirds in the table above with their expected counts under the null hypothesis. The further the actual counts are from their expected values, on the whole, the bigger this test statistic will be. For the gory (they are not that gory!) details on how this is done, see section 4 below but do note that, while these are interesting, if you find that kind of thing interesting, as I do, you do not need to be familiar with them to be able to apply a chi-square test. What you do need to know is when it is OK to use one, and when it is not, as is true for any statistical test.\nWe’ll turn to that issue now:\nProviding a number of conditions are met by the data (principally, that they are count data, that all the cell values are greater than or equal to about five and that they are all independent ie any ladybird contributes to the count of only one cell), this test statistic \\(X^2\\) has a so-called ‘chi-squared’ distribution. This is a known mathematical distribution, which makes it possible to calculate the probability that the statistic would be as big as it is, or bigger, if the null hypothesis were true. We call this probability the p-value.\nThis is generally how statistical tests work. They take your data and use it in a carefully chosen way to calculate some number that in general is called a test statistic but which is referred to by different names when calculated for particular tests. How it is calculated depends on the test and these days we never have to manually do the calculations ourselves. That’s taken care of by software like R. Providing the data meet certain criteria, the statistic will typically have a known probability distribution. This means that the probability that it will exceed a given value if the null hypothesis is true can be calculated. This probability is the p-value. If the p-value is very small, and by that we typically mean less than 0.05 or 0.01, then we can reject the null hypothesis.\nWhen we run a chi-square test in R on the data in the table above it gives us this as output:\n\nchisq.test(lady.mat)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  lady.mat\nX-squared = 19, df = 1, p-value = 1e-05\n\n\n\n\n\n\n\n\nNote\n\n\n\nYates continuity correction This is mentioned is the output of the test. What does it mean? It adjusts for the fact that our data are discrete and the chi-square distribution that we are using to calculate the p-values is continuous. That’s it.\n\n\nConclusion\nStudy the output of the chi-square test. Note that you are given a test-statistic (here called Chi-squared/X-squared) and a number of degrees of freedom (df) (in some tests you are given more than one of these). This is the number of independent pieces of information used to calculate the test statistic. Lastly, you are a given a p-value. This is the probability that you would have got a chi-squared value as big or bigger than the one you got if the null hypothesis were true. Here the null hypothesis is that there is no association between ladybird colour and location. Put another way, it is, roughly speaking the probability of getting the data you actually got if the null hypothesis were true.\nHere, the p-value is much less than 0.05, so we can safely reject the null hypothesis. The ladybird colour does not appear to be independent of the setting.\nAn appropriate way to report these data would be:\n‘Ladybird colour morphs are not equally common in the two habitats (Chi-sq =19.3, df = 1, p&lt;0.001)’\n\n\n2.2.2 Example - are two species independent?\nA researcher investigates whether two species A and B are associated with one another. If one is present at a site, does the other tend to be present, and if one is absent, does the other tend to be absent?. If the species were not associated with one another, then the presence of one would say nothing about the likely presence or absence of the other. Their occurrences would be independent.\nThe researcher goes to 100 sites and finds the following:\n\n\n\nWhat was found\nNumber\n\n\n\n\nA present, B present\n33.\n\n\nA present, B absent\n28.\n\n\nB present, A absent\n12.\n\n\nA absent, B absent\n27.\n\n\n\nThey enter these into a 2 x 2 contingency table in R, as follows:\n\nAB &lt;- matrix(c(33,28,12,27),nrow = 2)\nAB # R calls this a matrix - we will refer to it as a table.\n\n     [,1] [,2]\n[1,]   33   12\n[2,]   28   27\n\n\nThink about what each row and column in this table represents: as we have constructed it, columns relate to A and rows relate to B. The left hand column gives counts of sites where A was present, the right hand column gives counts where it was absent. The top row gives gives counts of sites where B was present, the bottom row gives counts of sites where it was absent.\n\nIt is valid here to use a chi square test for evidence of an association between species A and species B. Why?\n\nBecause the data are in the form of counts, each count is independent of the others and no count is less than 5.\nWe use the matrix AB as the argument for chisq.test() in R:\n\nchisq.test(AB)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  AB\nX-squared = 4, df = 1, p-value = 0.04\n\n\n\nWhat conclusion do we reach about the independence or otherwise of A and B?\n\nWe find p &lt; 0.05, so we reject the null hypothesis of no association and can say that there is evidence, at the 5% significance level, that species A and B are associated.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Chi-squared analysis of count data</span>"
    ]
  }
]